# Configuration for GPT-4o model
model:
  name: "gpt-4o"
  version: "2024-08-06"
  context_length: 128000
  max_tokens: 4096
  default_temperature: 0.7
  timeout: 30

apd_parameters:
  # Temperature settings
  tau_min: 0.3
  tau_max: 0.8
  tau_a: 0.5
  beta: 2.0
  
  # Novelty detection
  gamma: 0.3
  novelty_metric: "cosine"
  novelty_window_size: 2
  
  # SPRT configuration
  sprt:
    p0: 0.2
    p1: 0.6
    alpha: 0.05
    beta: 0.05
  
  # Iteration limits
  max_iterations: 3
  min_iterations: 1

generation_parameters:
  frequency_penalty: 0.0
  presence_penalty: 0.0
  top_p: 0.95
  stop_sequences: ["\n\n", "###", "---"]
  
  # Response formatting
  response_format: "text"
  max_retries: 3
  retry_delay: 2

optimization:
  # Batch processing
  batch_size: 1
  parallel_requests: 1
  
  # Caching
  enable_caching: true
  cache_ttl: 3600
  
  # Cost optimization
  enable_token_count: true
  max_tokens_per_minute: 10000

monitoring:
  # Logging
  log_level: "INFO"
  enable_metrics: true
  metrics_interval: 60
  
  # Performance tracking
  track_latency: true
  track_token_usage: true
  track_quality_metrics: true

prompt_config:
  # Prompt templates
  opposition_prompt: "prompts/opposition_prompt.txt"
  unification_prompt: "prompts/unification_prompt.txt"
  novelty_prompt: "prompts/novelty_assessment_prompt.txt"
  
  # Prompt optimization
  enable_prompt_compression: false
  max_prompt_tokens: 8000
  system_message: "You are an expert problem solver and critical thinker."

safety:
  # Content moderation
  enable_moderation: true
  moderation_threshold: 0.8
  max_rejection_count: 3
  
  # Ethical constraints
  allow_controversial_topics: false
  max_controversy_level: 0.3

cost_management:
  # Rate limiting
  requests_per_minute: 50
  tokens_per_minute: 40000
  
  # Budget control
  max_cost_per_session: 0.50
  max_cost_per_day: 10.00
  currency: "USD"